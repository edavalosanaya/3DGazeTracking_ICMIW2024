# 3D Gaze Tracking for Studying Collaborative Interactions in Mixed-Reality Environments
Created by <a href="http://ai.stanford.edu/~hewang/" target="_blank">Eduardo Davalos</a>, <a href="http://ai.stanford.edu/~ssrinath/" target="_blank">Yike Zhang</a>, <a href="http://stanford.edu/~jingweih/" target="_blank">Ashwin T.S.</a>, <a href="https://github.com/julienvalentin" target="_blank">Joyce Horn Fonteles</a>, <a href="https://shurans.github.io/index.html" target="_blank">Umesh Timalsina</a>,  <a href="https://geometry.stanford.edu/member/guibas/" target="_blank">Guatam Biswas</a> from <a href="https://www.stanford.edu/" target="_blank">Vanderbilt University</a>

![Teaser](/misc/imgs/Gaze%20Estimation-Teaser.png)

## Citation
If you find our work useful in your research, please consider citing:

## Introduction

This is a implementation of [**3D Gaze Tracking for Studying Collaborative Interactions in Mixed-Reality Environments**]().

For more information, please visit the [**project page**]().

## Requirements
This code has been tested with
* Python 3.10
* Pytorch