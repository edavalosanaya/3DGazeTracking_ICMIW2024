{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 09:45:04.164690: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-12 09:45:04.166985: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-12 09:45:04.192339: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-12 09:45:04.192360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-12 09:45:04.193237: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-12 09:45:04.197980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-12 09:45:05.212065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "os.environ['DEEPFACE_LOG_LEVEL'] = str(logging.ERROR)\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'ICMI2024'\n",
    "REID_DB = DATA_DIR / 'reid' / 'db'\n",
    "OUTPUT_DIR = DATA_DIR / 'reid' / 'tables'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From video, create the cropped face images\n",
    "def generate_cropped_faces(video_file, tracking_file, output_dir):\n",
    "    assert video_file.exists()\n",
    "    assert tracking_file.exists()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    df = pd.read_csv(tracking_file)\n",
    "\n",
    "    for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "        \n",
    "        # Load frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get the detected faces\n",
    "        detected_faces = df[df['Frame'] == i]\n",
    "\n",
    "        for (j, row) in detected_faces.iterrows():\n",
    "            crop = frame[int(row['Y']):int(row['Y']+row['Height']), int(row['X']):int(row['X']+row['Width'])]\n",
    "            # cv2.imshow('crop', crop)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            cv2.imwrite(str(output_dir / f'frame_{i}_id_{int(row[\"Student_ID\"])}.png'), crop)\n",
    "\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1'\n",
    "# )\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-second-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g2'\n",
    "# )\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd2g1'\n",
    "# )\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-second-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd2g2'\n",
    "# )\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13464/13464 [00:12<00:00, 1121.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df length: 78894, Video length: 13464\n",
      "Exists: 78894/78894 = 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "def sanity_check(video_file: pathlib.Path, tracking_file: pathlib.Path, cropped_face_dir: pathlib.Path):\n",
    "    assert video_file.exists()\n",
    "    assert tracking_file.exists()\n",
    "    assert cropped_face_dir.exists()\n",
    "\n",
    "    # Load the file\n",
    "    df = pd.read_csv(tracking_file)\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Get the face numpy array\n",
    "    exists = 0\n",
    "    for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "        \n",
    "        # Get the detected faces\n",
    "        detected_faces = df[df['Frame'] == i]\n",
    "\n",
    "        for (j, row) in detected_faces.iterrows():\n",
    "            face_crop = cropped_face_dir / f\"frame_{i}_id_{int(row['Student_ID'])}.png\"\n",
    "            if face_crop.exists():\n",
    "                exists += 1\n",
    "\n",
    "    print(f\"Df length: {len(df)}, Video length: {LENGTH}\")\n",
    "    print(f\"Exists: {exists}/{len(df)} = {exists/len(df):.2f}\")\n",
    "\n",
    "sanity_check(\n",
    "    DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\n",
    "    DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cropped images: 52141\n"
     ]
    }
   ],
   "source": [
    "# 52,141 items according to file system\n",
    "dir = DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1'\n",
    "print(f\"Total cropped images: {len([x for x in dir.iterdir()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12029/12029 [02:15<00:00, 89.03it/s] \n",
      "100%|██████████| 18834/18834 [04:03<00:00, 77.34it/s] \n"
     ]
    }
   ],
   "source": [
    "SIZE_REQ = 30\n",
    "INDIVIDUAL_THRESHOLD = 1\n",
    "DISTANCE_THRESHOLD = 0.5\n",
    "\n",
    "def reid_process(video_file: pathlib.Path, tracking_file: pathlib.Path, cropped_face_dir: pathlib.Path, output_file: pathlib.Path):\n",
    "    assert video_file.exists()\n",
    "    assert tracking_file.exists()\n",
    "    assert cropped_face_dir.exists()\n",
    "\n",
    "    # Load the file\n",
    "    df = pd.read_csv(tracking_file)\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create output folder to verify users REID\n",
    "    reid_folder = cropped_face_dir.parent / f\"{cropped_face_dir.name}_reid\"\n",
    "    if reid_folder.exists():\n",
    "        shutil.rmtree(reid_folder)\n",
    "    os.makedirs(reid_folder, exist_ok=True)\n",
    "    for id in ['s1','s2','s3','s4','s5','s6','s7','r1', 'r2','teacher']:\n",
    "        os.makedirs(reid_folder/id, exist_ok=True)\n",
    "\n",
    "    # Create reid container\n",
    "    reid_container = {'cropped_file': [], 'reid': [], 'distance': [], 'comment': []}\n",
    "\n",
    "    tracked_id_to_reid_mapping = {}\n",
    "\n",
    "    # Get the face numpy array\n",
    "    for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Get the detected faces\n",
    "            detected_faces = df[df['Frame'] == i]\n",
    "\n",
    "            # Create container to ensure frame consistency\n",
    "            reid_detections = {}\n",
    "\n",
    "            for (j, row) in detected_faces.iterrows():\n",
    "\n",
    "                tracked_id = int(row['Student_ID'])\n",
    "\n",
    "                if tracked_id in tracked_id_to_reid_mapping:\n",
    "                    # reid_container['cropped_file'].append(face_crop.name)\n",
    "                    # reid_container['reid'].append(tracked_id_to_reid_mapping[tracked_id])\n",
    "                    # reid_container['distance'].append(None)\n",
    "                    # reid_container['comment'].append(\"Retracked\")\n",
    "                    continue\n",
    "\n",
    "                filename = f\"frame_{i}_id_{tracked_id}.png\"\n",
    "                face_crop = cropped_face_dir / filename\n",
    "                assert face_crop.exists()\n",
    "                crop = cv2.imread(str(face_crop))\n",
    "\n",
    "                # If the image is to small, not worth the trouble\n",
    "                h,w = crop.shape[:2]\n",
    "                if (h < SIZE_REQ or w < SIZE_REQ):\n",
    "                    # reid_container['cropped_file'].append(face_crop.name)\n",
    "                    # reid_container['reid'].append(None)\n",
    "                    # reid_container['distance'].append(None)\n",
    "                    # reid_container['comment'].append(\"image size too small\")\n",
    "                    continue\n",
    "\n",
    "                # cv2.imshow('crop', crop)\n",
    "                # cv2.waitKey(1)\n",
    "\n",
    "                match_df = DeepFace.find(\n",
    "                    img_path=crop,\n",
    "                    db_path=REID_DB,\n",
    "                    model_name=\"Facenet512\",\n",
    "                    distance_metric=\"euclidean_l2\",\n",
    "                    enforce_detection=False,\n",
    "                    silent=True,\n",
    "                    threshold=INDIVIDUAL_THRESHOLD\n",
    "                )[0]\n",
    "\n",
    "                ids = match_df['identity'].str.split(\"/\").str.get(-2)\n",
    "                match_df['identity'] = ids\n",
    "\n",
    "                if len(ids) == 0:\n",
    "                    # reid_container['cropped_file'].append(face_crop.name)\n",
    "                    # reid_container['reid'].append(None)\n",
    "                    # reid_container['distance'].append(None)\n",
    "                    # reid_container['comment'].append(\"Failed REID: No Match\")\n",
    "                    pass\n",
    "                else:\n",
    "\n",
    "                    # Possible success\n",
    "                    mode_df = match_df.groupby(\"identity\")['distance'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "                    # Step 3: Find the 'identity' with the lowest mode value of 'distance'\n",
    "                    lowest_mode_identity = mode_df.loc[mode_df['distance'].idxmin()]\n",
    "\n",
    "                    # Compute counts of each 'identity'\n",
    "                    # counts = match_df['identity'].value_counts().reset_index()\n",
    "                    # counts.columns = ['identity', 'count']\n",
    "\n",
    "                    reid_detections[face_crop.name] = {\n",
    "                        \"tracked_id\": tracked_id,\n",
    "                        \"filepath\": face_crop.name,\n",
    "                        \"image\": crop,\n",
    "                        \"reid\": lowest_mode_identity['identity'],\n",
    "                        \"distance\": lowest_mode_identity['distance'],\n",
    "                    }\n",
    "            \n",
    "            # Group by 'reid' and select the row with the highest 'distance' in each group\n",
    "            if reid_detections:\n",
    "                reid_df = pd.DataFrame.from_dict(reid_detections, orient=\"index\")\n",
    "                selected_entries_df = reid_df.groupby('reid', as_index=False).apply(lambda x: x.loc[x['distance'].idxmax()])\n",
    "                selected_entries_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Save the entry\n",
    "                for (k, row) in selected_entries_df.iterrows():\n",
    "\n",
    "                    # Enter the data\n",
    "                    reid_container['cropped_file'].append(row['filepath'])\n",
    "                    reid_container['reid'].append(row['reid'])\n",
    "                    reid_container['distance'].append(row['distance'])\n",
    "                    reid_container['comment'].append(\"\")\n",
    "\n",
    "                    # Save the image as well\n",
    "                    new_fp = reid_folder / row['reid'] / row['filepath']\n",
    "                    cv2.imwrite(str(new_fp), row['image'])\n",
    "\n",
    "                    # Save in the mapping\n",
    "                    tracked_id_to_reid_mapping[row[\"tracked_id\"]] = row['reid']\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"KeyboardInterrupt detected, saving data\")\n",
    "            break\n",
    "\n",
    "    # Save the container\n",
    "    reid_df = pd.DataFrame(reid_container)\n",
    "    reid_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Save the mapping from tracked id to REID tag\n",
    "    with open(output_file.parent / f\"{output_file.stem}.json\", \"w\") as f:\n",
    "        json.dump(tracked_id_to_reid_mapping, f, indent=4)\n",
    "\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1',\n",
    "#     OUTPUT_DIR / 'd1g1-cam2.csv'\n",
    "# )\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-second-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g2',\n",
    "#     OUTPUT_DIR / 'd1g2-cam2.csv'\n",
    "# )\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd2g1',\n",
    "#     OUTPUT_DIR / 'd2g1-cam2.csv'\n",
    "# )\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-second-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd2g2',\n",
    "#     OUTPUT_DIR / 'd2g2-cam2.csv'\n",
    "# )\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 69 entries\n",
      "Deleted 58 entries\n",
      "Deleted 88 entries\n",
      "Deleted 132 entries\n"
     ]
    }
   ],
   "source": [
    "# Process the manually cleaned REID, report accuracy, and update JSON\n",
    "\n",
    "def clean_reid(reid_dir: pathlib.Path, reid_json: pathlib.Path):\n",
    "    assert reid_dir.exists()\n",
    "    assert reid_json.exists()\n",
    "\n",
    "    # Load the JSON\n",
    "    with open(reid_json, \"r\") as f:\n",
    "        tracked_id_to_reid_mapping = json.load(f)\n",
    "\n",
    "    # Make a copy of the tracked_id_to_reid_mapping\n",
    "    tracked_id_to_reid_mapping_copy = tracked_id_to_reid_mapping.copy()\n",
    "\n",
    "    # Iterate through the reid\n",
    "    for folder in reid_dir.iterdir():\n",
    "        for file in folder.iterdir():\n",
    "            # Get the tracking ID from the filename\n",
    "            tracked_id = file.stem.split(\"_\")[-1]\n",
    "\n",
    "            # Update the mapping\n",
    "            if tracked_id_to_reid_mapping[tracked_id] != folder.name:\n",
    "                tracked_id_to_reid_mapping_copy[tracked_id] = folder.name\n",
    "                # print(f\"Updated {tracked_id} from {tracked_id_to_reid_mapping[tracked_id]} to {folder.name}\")\n",
    "\n",
    "    # Check for deleted entries\n",
    "    to_delete = 0\n",
    "    for k in tracked_id_to_reid_mapping:\n",
    "        delete = True\n",
    "        for folder in reid_dir.iterdir():\n",
    "            tracked_ids_in_folder = [int(x.stem.split(\"_\")[-1]) for x in folder.iterdir()]\n",
    "            if int(k) in tracked_ids_in_folder:\n",
    "                delete = False\n",
    "                break\n",
    "        if delete:\n",
    "            del tracked_id_to_reid_mapping_copy[k]\n",
    "            to_delete += 1\n",
    "\n",
    "    # Report\n",
    "    print(f\"Deleted {to_delete} entries\")\n",
    "\n",
    "    # print(tracked_id_to_reid_mapping)\n",
    "    # print(tracked_id_to_reid_mapping_copy)\n",
    "\n",
    "    # After the loop, compare the two dictionaries\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    false = 0\n",
    "    total = len(tracked_id_to_reid_mapping)\n",
    "\n",
    "    # Track also which REID tags are the most challenging\n",
    "    correct_reid = []\n",
    "    incorrect_reid = []\n",
    "\n",
    "    for k in tracked_id_to_reid_mapping:\n",
    "        if k not in tracked_id_to_reid_mapping_copy:\n",
    "            false += 1\n",
    "        elif tracked_id_to_reid_mapping[k] == tracked_id_to_reid_mapping_copy[k]:\n",
    "            correct += 1\n",
    "            correct_reid.append(tracked_id_to_reid_mapping[k])\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            incorrect_reid.append(tracked_id_to_reid_mapping[k])\n",
    "\n",
    "    # Save the new JSON\n",
    "    new_reid_json_fp = reid_json.parent / f\"{reid_json.stem}_cleaned.json\"\n",
    "    with open(new_reid_json_fp, \"w\") as f:\n",
    "        json.dump(tracked_id_to_reid_mapping_copy, f, indent=4)\n",
    "\n",
    "    # Save the report\n",
    "    report_fp = reid_json.parent / f\"{reid_json.stem}_report.csv\"\n",
    "    report_df = pd.DataFrame({\n",
    "        \"correct\": [correct, correct/total],\n",
    "        \"incorrect\": [incorrect, incorrect/total],\n",
    "        \"false\": [false, false/total],\n",
    "    })\n",
    "\n",
    "    report_df.to_csv(report_fp, index=False, float_format=\"%.3f\")\n",
    "\n",
    "    # Create a report that includes individual REID tags\n",
    "    correct_counts = pd.Series(correct_reid).value_counts()\n",
    "    incorrect_counts = pd.Series(incorrect_reid).value_counts()\n",
    "\n",
    "    # Make sure that all REID tags are included (r1, r2, s1, s2, s3, s4, s5, s6, s7, teacher)\n",
    "    for tag in ['s1','s2','s3','s4','s5','s6','s7','r1', 'r2','teacher']:\n",
    "        if tag not in correct_counts:\n",
    "            correct_counts[tag] = 0\n",
    "        if tag not in incorrect_counts:\n",
    "            incorrect_counts[tag] = 0\n",
    "\n",
    "    # Compute correct/incorrect ratio\n",
    "    ratio = correct_counts / (correct_counts + incorrect_counts)\n",
    "\n",
    "    # Add back the counts and incorrect counts\n",
    "    ratio = pd.concat([correct_counts, incorrect_counts, ratio], axis=1)\n",
    "    ratio.columns = [\"correct\", \"incorrect\", \"ratio\"]\n",
    "\n",
    "    ratios_fp = reid_json.parent / f\"{reid_json.stem}_ratios.csv\"\n",
    "    ratio.to_csv(ratios_fp, index_label=\"reid\")\n",
    "                \n",
    "\n",
    "clean_reid(\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1_reid_cleaned',\n",
    "    OUTPUT_DIR / 'd1g1-cam2.json'\n",
    ")\n",
    "\n",
    "clean_reid(\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd1g2_reid_cleaned',\n",
    "    OUTPUT_DIR / 'd1g2-cam2.json'\n",
    ")\n",
    "\n",
    "clean_reid(\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd2g1_reid_cleaned',\n",
    "    OUTPUT_DIR / 'd2g1-cam2.json'\n",
    ")\n",
    "\n",
    "clean_reid(\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd2g2_reid_cleaned',\n",
    "    OUTPUT_DIR / 'd2g2-cam2.json'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ettk_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
