{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different environment\n",
    "# Instead of opencv-python, use opencv-python-headless (requiring a different environment)\n",
    "\n",
    "# https://github.com/edavalosanaya/plot3d\n",
    "import plot3d\n",
    "\n",
    "# In a separate terminal, run to start the server:\n",
    "# plot3d\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imutils\n",
    "import trimesh # install pyembree for a ray tracing speedup of 50x\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'AIED2024'\n",
    "\n",
    "# Append ZoeDepth to path\n",
    "import sys\n",
    "sys.path.append('ZoeDepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def depth_to_points(depth, R=None, t=None):\n",
    "\n",
    "    K = get_intrinsics(depth.shape[1], depth.shape[2])\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    if R is None:\n",
    "        R = np.eye(3)\n",
    "    if t is None:\n",
    "        t = np.zeros(3)\n",
    "\n",
    "    # M converts from your coordinate to PyTorch3D's coordinate system\n",
    "    M = np.eye(3)\n",
    "    M[0, 0] = -1.0\n",
    "    M[1, 1] = -1.0\n",
    "\n",
    "    height, width = depth.shape[1:3]\n",
    "\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    coord = np.stack(np.meshgrid(x, y), -1)\n",
    "    coord = np.concatenate((coord, np.ones_like(coord)[:, :, [0]]), -1)  # z=1\n",
    "    coord = coord.astype(np.float32)\n",
    "    # coord = torch.as_tensor(coord, dtype=torch.float32, device=device)\n",
    "    coord = coord[None]  # bs, h, w, 3\n",
    "\n",
    "    D = depth[:, :, :, None, None]\n",
    "    # print(D.shape, Kinv[None, None, None, ...].shape, coord[:, :, :, :, None].shape )\n",
    "    pts3D_1 = D * Kinv[None, None, None, ...] @ coord[:, :, :, :, None]\n",
    "    # pts3D_1 live in your coordinate system. Convert them to Py3D's\n",
    "    pts3D_1 = M[None, None, None, ...] @ pts3D_1\n",
    "    # from reference to targe tviewpoint\n",
    "    pts3D_2 = R[None, None, None, ...] @ pts3D_1 + t[None, None, None, :, None]\n",
    "    # pts3D_2 = pts3D_1\n",
    "    # depth_2 = pts3D_2[:, :, :, 2, :]  # b,1,h,w\n",
    "    return pts3D_2[:, :, :, :3, 0][0]\n",
    "\n",
    "def depth_edges_mask(depth):\n",
    "    \"\"\"Returns a mask of edges in the depth map.\n",
    "    Args:\n",
    "    depth: 2D numpy array of shape (H, W) with dtype float32.\n",
    "    Returns:\n",
    "    mask: 2D numpy array of shape (H, W) with dtype bool.\n",
    "    \"\"\"\n",
    "    # Compute the x and y gradients of the depth map.\n",
    "    depth_dx, depth_dy = np.gradient(depth)\n",
    "    # Compute the gradient magnitude.\n",
    "    depth_grad = np.sqrt(depth_dx ** 2 + depth_dy ** 2)\n",
    "    # Compute the edge mask.\n",
    "    mask = depth_grad > 0.05\n",
    "    return mask\n",
    "\n",
    "def create_triangles(h, w, mask=None):\n",
    "    \"\"\"Creates mesh triangle indices from a given pixel grid size.\n",
    "        This function is not and need not be differentiable as triangle indices are\n",
    "        fixed.\n",
    "    Args:\n",
    "    h: (int) denoting the height of the image.\n",
    "    w: (int) denoting the width of the image.\n",
    "    Returns:\n",
    "    triangles: 2D numpy array of indices (int) with shape (2(W-1)(H-1) x 3)\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(range(w - 1), range(h - 1))\n",
    "    tl = y * w + x\n",
    "    tr = y * w + x + 1\n",
    "    bl = (y + 1) * w + x\n",
    "    br = (y + 1) * w + x + 1\n",
    "    triangles = np.array([tl, bl, tr, br, tr, bl])\n",
    "    triangles = np.transpose(triangles, (1, 2, 0)).reshape(\n",
    "        ((w - 1) * (h - 1) * 2, 3))\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        triangles = triangles[mask[triangles].all(1)]\n",
    "    return triangles\n",
    "\n",
    "def get_mesh(image, depth, keep_edges=False):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pts3d = depth_to_points(depth[None])\n",
    "    pts3d = pts3d.reshape(-1, 3)\n",
    "\n",
    "    # Create a trimesh mesh from the points\n",
    "    # Each pixel is connected to its 4 neighbors\n",
    "    # colors are the RGB values of the image\n",
    "\n",
    "    verts = pts3d.reshape(-1, 3)\n",
    "    image = np.array(image)\n",
    "    if keep_edges:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1], mask=~depth_edges_mask(depth))\n",
    "    colors = image.reshape(-1, 3)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=triangles, vertex_colors=colors)\n",
    "\n",
    "    # Save as glb\n",
    "    return mesh\n",
    "\n",
    "def compute_3D_point(x, y, Z, H, W):\n",
    "    \"\"\"\n",
    "    Compute the 3D point in the camera coordinate system from an image coordinate and depth.\n",
    "\n",
    "    Parameters:\n",
    "    - x, y: The image coordinates (pixels)\n",
    "    - Z: The depth value (distance along the camera's viewing axis)\n",
    "    - f_x, f_y: The camera's focal lengths along the X and Y axes (pixels)\n",
    "    - c_x, c_y: The optical center of the camera (pixels)\n",
    "\n",
    "    Returns:\n",
    "    A tuple (X, Y, Z) representing the 3D point in the camera coordinate system.\n",
    "    \"\"\"\n",
    "    # \n",
    "    fy = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    fx = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "\n",
    "    # Normalize the 2D coordinates\n",
    "    x_prime = (x - cx) / fx\n",
    "    y_prime = (y - cy) / fy\n",
    "\n",
    "    # Apply the depth to get the 3D point\n",
    "    X = x_prime * Z\n",
    "    Y = y_prime * Z\n",
    "\n",
    "    return np.array([X, Y, Z])\n",
    "\n",
    "\n",
    "def draw_gaze(x, y, length, img, pitchyaw, thickness=2, color=(255, 255, 0),sclae=2.0):\n",
    "    \"\"\"Draw gaze angle on given image with a given eye positions.\"\"\"\n",
    "    pos = (int(x), int(y))\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    dx = -length * np.sin(pitchyaw[0]) * np.cos(pitchyaw[1])\n",
    "    dy = -length * np.sin(pitchyaw[1])\n",
    "    cv2.arrowedLine(img, tuple(np.round(pos).astype(np.int32)),\n",
    "                   tuple(np.round([pos[0] + dx, pos[1] + dy]).astype(int)), color,\n",
    "                   thickness, cv2.LINE_AA, tipLength=0.18)\n",
    "    return img\n",
    "\n",
    "def create_arrow(shaft_length=1.0, shaft_radius=0.01, head_length=0.2, head_radius=0.1, thickness=1):\n",
    "    \"\"\"\n",
    "    Create an arrow mesh.\n",
    "    \n",
    "    Parameters:\n",
    "    - shaft_length: Length of the shaft.\n",
    "    - shaft_radius: Radius of the shaft.\n",
    "    - head_length: Length of the head.\n",
    "    - head_radius: Radius of the head.\n",
    "    \n",
    "    Returns:\n",
    "    - A trimesh object representing the arrow.\n",
    "    \"\"\"\n",
    "    # Create the shaft of the arrow (cylinder)\n",
    "    shaft = trimesh.creation.cylinder(radius=shaft_radius*thickness, height=shaft_length, sections=32)\n",
    "    shaft.apply_translation((0, 0, shaft_length/2))\n",
    "    \n",
    "    # Create the head of the arrow (cone)\n",
    "    head = trimesh.creation.cone(radius=head_radius*thickness, height=head_length*thickness, sections=32)\n",
    "    head.apply_translation((0, 0, shaft_length))\n",
    "    \n",
    "    # Combine the shaft and the head\n",
    "    arrow = trimesh.util.concatenate([shaft, head])\n",
    "\n",
    "    arrow.visual.face_colors = [1, 1, 1, 0.5]\n",
    "    arrow.visual.vertex_colors = [1, 1, 1, 0.5]\n",
    "    \n",
    "    return arrow\n",
    "\n",
    "\n",
    "def create_oriented_arrow(origin, pitch, yaw, length=1.0, thickness=1):\n",
    "\n",
    "    # Convert pitch, yaw, and roll to rotvec\n",
    "    rotation = R.from_euler('xyz', [0, pitch, yaw])\n",
    "    initial_vector = np.array([0,0,1])\n",
    "\n",
    "    # Compute the endpoint based on origin, pitch, yaw, and length\n",
    "    endpoint = rotation.apply(initial_vector)*length\n",
    "    \n",
    "    # Create an arrow mesh\n",
    "    # arrow = trimesh.creation.arrow(radius=0.05, height=length)\n",
    "    arrow = create_arrow(length, thickness=5)\n",
    "    \n",
    "    # Compute the direction vector for the arrow\n",
    "    direction = endpoint - origin\n",
    "    direction /= np.linalg.norm(direction) # Normalize the direction vector\n",
    "    \n",
    "    # Compute the rotation needed to align the arrow with the direction vector\n",
    "    # Default arrow direction is along the z-axis (0, 0, 1)\n",
    "    # default_direction = np.array([0, 0, 1])\n",
    "    # rotation_vector = np.cross(default_direction, direction)\n",
    "    # rotation_angle = np.arccos(np.dot(default_direction, direction))\n",
    "    # rotation = R.from_rotvec(rotation_vector * rotation_angle)\n",
    "    \n",
    "    # Apply rotation to the arrow\n",
    "    # arrow.apply_transform(rotation.as_matrix())\n",
    "    rt = np.eye(4)\n",
    "    rt[:3,:3] = rotation.as_matrix()\n",
    "    rt[:3,-1] = origin\n",
    "    arrow.apply_transform(rt)\n",
    "    \n",
    "    return arrow, direction\n",
    "\n",
    "def find_closest_intersected_mesh(scene, origin, direction):\n",
    "    \"\"\"\n",
    "    Find the closest mesh in the scene that a ray intersects with, excluding a specific mesh by name.\n",
    "\n",
    "    Args:\n",
    "    - scene: The trimesh.Scene containing all meshes.\n",
    "    - origin: The starting point of the ray.\n",
    "    - direction: The direction vector of the ray\n",
    "\n",
    "    Returns:\n",
    "    - The name of the closest mesh intersected by the ray, or None if no intersection is found.\n",
    "    \"\"\"\n",
    "    closest_mesh_name = None\n",
    "    closest_distance = np.inf\n",
    "\n",
    "    for mesh_name, mesh in scene.geometry.items():\n",
    "\n",
    "        # Check for intersections with this mesh\n",
    "        locations, _, _ = mesh.ray.intersects_location(\n",
    "            ray_origins=[origin],\n",
    "            ray_directions=[direction]\n",
    "        )\n",
    "\n",
    "        # Find the closest intersection point (if any)\n",
    "        for location in locations:\n",
    "            distance = np.linalg.norm(location - origin)\n",
    "            if distance < closest_distance:\n",
    "                closest_mesh_name = mesh_name\n",
    "                closest_distance = distance\n",
    "\n",
    "    return closest_mesh_name\n",
    "\n",
    "def find_closest_intersected_mesh_via_intersection(scene, arrow, origin):\n",
    "    closest_mesh_name = None\n",
    "    closest_distance = np.inf\n",
    "\n",
    "    for mesh_name, mesh in scene.geometry.items():\n",
    "\n",
    "        # Obtain intersection with arrow\n",
    "        int_mesh = arrow.intersection(mesh)\n",
    "\n",
    "        if int_mesh.is_empty:\n",
    "            continue\n",
    "\n",
    "        # Find the closest intersection point (if any)\n",
    "        distance = np.linalg.norm(int_mesh.centroid - origin)\n",
    "        if distance < closest_distance:\n",
    "            closest_mesh_name = mesh_name\n",
    "            closest_distance = distance\n",
    "\n",
    "    return closest_mesh_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10314 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10314 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "VISUALIZE = True\n",
    "\n",
    "if VISUALIZE:\n",
    "    # Create a plot\n",
    "    plot = plot3d.Plot(port=9001)\n",
    "\n",
    "    # Reset the 3D Plot\n",
    "    plot.reset()\n",
    "\n",
    "sphere = trimesh.creation.uv_sphere(radius=0.25)\n",
    "sphere.visual.face_colors = [0, 0, 1, 0.5]\n",
    "sphere.visual.vertex_colors = [0, 0, 1, 0.5]\n",
    "\n",
    "HUMAN_BOX_RATIO = 1.2\n",
    "bbox = trimesh.creation.box(extents=np.array([4, 10, 4])*HUMAN_BOX_RATIO)\n",
    "r = R.from_euler('xyz', np.radians(np.array([-10,0,0])))\n",
    "t = np.array([0.2, 1.3, -0.2])*4\n",
    "rt = np.eye(4)\n",
    "rt[:3, :3] = r.as_matrix()\n",
    "rt[:3, 3] = t\n",
    "bbox.apply_transform(rt)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PersonGaze:\n",
    "    id: int\n",
    "    tracked_id: int\n",
    "    bbox: trimesh.Trimesh\n",
    "    arrow: trimesh.Trimesh\n",
    "    origin: np.ndarray\n",
    "    direction: np.ndarray\n",
    "    pitch: float\n",
    "    yaw: float\n",
    "\n",
    "\n",
    "arrow_color_map = {\n",
    "    \"display\": [0, 1, 0, 0.5],\n",
    "    \"floor\": [0, 0, 1, 0.5],\n",
    "}\n",
    "\n",
    "\n",
    "def process(\n",
    "        tracking_file: pathlib.Path, \n",
    "        vid_file: pathlib.Path, \n",
    "        depth_file: pathlib.Path,\n",
    "        gaze_file: pathlib.Path,\n",
    "        display_r: np.ndarray,\n",
    "        display_t: np.ndarray\n",
    "    ):\n",
    "    assert tracking_file.exists()\n",
    "    assert vid_file.exists()\n",
    "    assert depth_file.exists()\n",
    "    assert gaze_file.exists()\n",
    "\n",
    "    DISPLAY_RATIO = 80\n",
    "    display = trimesh.creation.box(extents=np.array([0.8, 0.25, 0.01])*DISPLAY_RATIO)\n",
    "    display.visual.face_colors = [0, 1, 0, 0.5]\n",
    "    display.visual.vertex_colors = [0, 1, 0, 0.5]\n",
    "\n",
    "    # Add the monitor rectangle\n",
    "    # X -> blue, Y -> green, Z -> yellow\n",
    "    r = R.from_euler('xyz', np.radians(display_r))\n",
    "    t = display_t\n",
    "    rt = np.eye(4)\n",
    "    rt[:3, :3] = r.as_matrix()\n",
    "    rt[:3, 3] = t\n",
    "    display.apply_transform(rt)\n",
    "    if VISUALIZE: plot.add_mesh(f'display', display)\n",
    "\n",
    "    FLOOR_RATIO = 70\n",
    "    floor = trimesh.creation.box(extents=np.array([2, 2, 0.01])*FLOOR_RATIO)\n",
    "    floor.visual.face_colors = [0, 0, 1, 0.5]\n",
    "    floor.visual.vertex_colors = [0, 0, 1, 0.5]\n",
    "\n",
    "    # Add the floor rectangle\n",
    "    r = R.from_euler('xyz', np.radians(np.array([82,0,0])))\n",
    "    t = np.array([0, 0, -22])*4\n",
    "    rt = np.eye(4)\n",
    "    rt[:3, :3] = r.as_matrix()\n",
    "    rt[:3, 3] = t\n",
    "    floor.apply_transform(rt)\n",
    "    # if VISUALIZE: plot.add_mesh(\"floor\", floor)\n",
    "\n",
    "    # Output file\n",
    "    output_file = gaze_file.parent / f\"{gaze_file.stem}_raytraced.csv\"\n",
    "    output_container = {'frame': [], 'src_tracked_id': [], 'dst_tracked_id': []}\n",
    "\n",
    "    # Load the gaze vectors and the corresponding CSV with BBox info\n",
    "    faces_df = pd.read_csv(tracking_file)\n",
    "    gaze_df = pd.read_csv(gaze_file)\n",
    "\n",
    "    # Load the RGB and depth videos\n",
    "    cap = cv2.VideoCapture(str(vid_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    depth_cap = cv2.VideoCapture(str(depth_file))\n",
    "\n",
    "    # Starting point\n",
    "    video_index = 3150 # 0 # 9450 \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, video_index)\n",
    "    depth_cap.set(cv2.CAP_PROP_POS_FRAMES, video_index)\n",
    "\n",
    "    try:\n",
    "\n",
    "        for i in tqdm(range(video_index, LENGTH), total=LENGTH-video_index):\n",
    "\n",
    "            print(i)\n",
    "\n",
    "            # Load frame\n",
    "            r_ret, rgb = cap.read()\n",
    "            d_ret, depth = depth_cap.read()\n",
    "\n",
    "            # cv2.imwrite(\"test.png\", rgb)\n",
    "            # cv2.imwrite(\"test_depth.png\", depth)\n",
    "\n",
    "            if not r_ret or not d_ret:\n",
    "                break\n",
    "\n",
    "            depth = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Get the gaze vector\n",
    "            faces = faces_df[faces_df['Frame'] == i]\n",
    "            gaze_vectors = gaze_df[gaze_df['frame'] == i]\n",
    "\n",
    "            # Mesh containers\n",
    "            persons = []\n",
    "            objs = {}\n",
    "\n",
    "            j = 0\n",
    "            for (_, face) in faces.iterrows():\n",
    "                # Get the gaze vector\n",
    "                # print(gaze_vectors)\n",
    "                gaze_vector = gaze_vectors[gaze_vectors['tracked_id'] == face[\"Student_ID\"]].iloc[0]\n",
    "                pitch = gaze_vector['pitch']\n",
    "                yaw = gaze_vector['yaw']\n",
    "\n",
    "                # Compute the centroid of the face\n",
    "                centroid = (face.X + face.Width/2, face.Y + face.Height/2)\n",
    "                centroid_depth = depth[int(centroid[1]), int(centroid[0])]\n",
    "                face_t = compute_3D_point(centroid[0], centroid[1], centroid_depth, depth.shape[0], depth.shape[1])\n",
    "                face_t[-1] = face_t[-1]*-1\n",
    "                face_t[0] = face_t[0]*-1\n",
    "                line_start = face_t.copy()\n",
    "\n",
    "                # 2D Data\n",
    "                # Draw in the 2D image\n",
    "                cv2.circle(rgb, (int(centroid[0]), int(centroid[1])), 5, (0, 255, 0), -1)\n",
    "\n",
    "                # Draw the id in 2D\n",
    "                # cv2.putText(rgb, f\"{j}\", (int(centroid[0]), int(centroid[1])), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)\n",
    "\n",
    "                # Draw the gaze vector\n",
    "                # draw_gaze(centroid[0], centroid[1], 100, rgb, [pitch, yaw], color=(0,255,0))\n",
    "\n",
    "                # 3D Data\n",
    "                # Make copy of spher and apply transform\n",
    "                hbbox = bbox.copy()\n",
    "                hbbox.apply_translation(face_t)\n",
    "                arrow, direction = create_oriented_arrow(line_start, pitch, yaw, length=30, thickness=15)\n",
    "\n",
    "                persons.append(\n",
    "                    PersonGaze(\n",
    "                        id=j,\n",
    "                        tracked_id=int(face[\"Student_ID\"]),\n",
    "                        bbox=hbbox, \n",
    "                        arrow=arrow, \n",
    "                        origin=face_t, \n",
    "                        direction=direction,\n",
    "                        pitch=pitch,\n",
    "                        yaw=yaw\n",
    "                    )\n",
    "                )\n",
    "                objs[int(face['Student_ID'])] = hbbox\n",
    "                j += 1\n",
    "\n",
    "            # Perform raytracing\n",
    "            for person in persons:\n",
    "                objs_exclude_person = {str(k):v for k,v in objs.items() if k != person.tracked_id}\n",
    "                objs_exclude_person.update({'display': display})\n",
    "                scene = trimesh.Scene()\n",
    "                for k,v in objs_exclude_person.items():\n",
    "                    scene.add_geometry(v, geom_name=k)\n",
    "\n",
    "                mesh_name = find_closest_intersected_mesh_via_intersection(\n",
    "                    scene,\n",
    "                    arrow=person.arrow,\n",
    "                    origin=person.origin\n",
    "                )\n",
    "                # scene.add_geometry(person.arrow, geom_name=f\"arrow-{person.id}\")\n",
    "                # scene.show(viewer=\"gl\", axis=True)\n",
    "                # print(f\"{person.id} -> {mesh_name}\")\n",
    "\n",
    "                assert mesh_name != person.tracked_id, \"The person is intersecting with itself\"\n",
    "\n",
    "                # Save to output\n",
    "                output_container['frame'].append(i)\n",
    "                output_container['src_tracked_id'].append(person.tracked_id)\n",
    "                output_container['dst_tracked_id'].append(mesh_name)\n",
    "\n",
    "                # Reduce the lenght of the arrow\n",
    "                person.arrow = create_oriented_arrow(person.origin, person.pitch, person.yaw, length=5, thickness=15)[0]\n",
    "\n",
    "                if mesh_name and VISUALIZE:\n",
    "                    if mesh_name in arrow_color_map:\n",
    "                        person.arrow.visual.face_colors = arrow_color_map[mesh_name]\n",
    "                        person.arrow.visual.vertex_colors = arrow_color_map[mesh_name]\n",
    "                    else:\n",
    "                        person.arrow.visual.face_colors = [1, 0, 0, 0.5]\n",
    "                        person.arrow.visual.vertex_colors = [1, 0, 0, 0.5]\n",
    "\n",
    "            # Show the scene\n",
    "            # if VISUALIZE:\n",
    "            #     debug_scene = trimesh.Scene()\n",
    "            #     for person in persons:\n",
    "            #         debug_scene.add_geometry(person.bbox, geom_name=f\"bbox-{person.id}\")\n",
    "            #         debug_scene.add_geometry(person.arrow, geom_name=f\"arrow-{person.id}\")\n",
    "            #         # Display and floor\n",
    "            #         debug_scene.add_geometry(display, geom_name=\"display\")\n",
    "            #         debug_scene.add_geometry(floor, geom_name=\"floor\")\n",
    "            #     # plot.add_mesh('debug_scene', debug_scene)\n",
    "            #     debug_scene.show(viewer=\"gl\", axis=True)\n",
    "\n",
    "\n",
    "            # Draw the arrows and bboxes later\n",
    "            if VISUALIZE:\n",
    "                for person in persons:\n",
    "                    # Draw spheres in the 3D plot\n",
    "                    if f\"bbox-{person.id}\" in plot.client.visuals:\n",
    "                        plot.update_mesh(f\"bbox-{person.id}\", person.bbox, drawFaces=False, drawEdges=True)\n",
    "                    else:\n",
    "                        plot.add_mesh(f\"bbox-{person.id}\", person.bbox, drawFaces=False, drawEdges=True)\n",
    "\n",
    "                    if f\"arrow-{person.id}\" in plot.client.visuals:\n",
    "                        plot.update_mesh(f\"arrow-{person.id}\", person.arrow)\n",
    "                    else:\n",
    "                        plot.add_mesh(f\"arrow-{person.id}\", person.arrow)\n",
    "                    \n",
    "                # Resize\n",
    "                sm_rgb = imutils.resize(rgb, width=500)\n",
    "                sm_depth = imutils.resize(depth, width=500)\n",
    "\n",
    "                mesh = get_mesh(sm_rgb, sm_depth, keep_edges=True)\n",
    "                mesh.apply_transform(trimesh.transformations.rotation_matrix(np.pi, [1,0,0]))\n",
    "\n",
    "                # Plot the frame\n",
    "                plot.plot_image(sm_rgb)\n",
    "                if i == video_index:\n",
    "                    plot.add_mesh('mesh', mesh)\n",
    "                else:\n",
    "                    plot.update_mesh('mesh', mesh)\n",
    "\n",
    "            # Save to PLY\n",
    "            # 400 camera distance\n",
    "            # filepath = DATA_DIR / 'mesh' / 'g1d1.ply'\n",
    "            # mesh.apply_translation(-mesh.centroid)\n",
    "            # mesh.export(str(filepath), file_type='ply')\n",
    "            # break\n",
    "            # time.sleep(1)\n",
    "\n",
    "            break\n",
    "                    \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "                \n",
    "    # Save the output\n",
    "    # output_df = pd.DataFrame(output_container)\n",
    "    # output_df = output_df.sort_values(by=['frame', 'src_tracked_id'])\n",
    "    # output_df.to_csv(output_file, index=False)\n",
    "\n",
    "process(\n",
    "    DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "    DATA_DIR / \"videos\" / \"day1\" / \"block-a-blue-day1-first-group-cam2.mp4\",\n",
    "    DATA_DIR / 'depths' / 'day1' / \"group1-depth-cam2.mp4\",\n",
    "    DATA_DIR / 'gaze_vectors' / \"gaze_vector_d1g1.csv\",\n",
    "    np.array([30,110,30]),\n",
    "    np.array([-3, 0, -9])*4\n",
    ")\n",
    "\n",
    "# process(\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / \"videos\" / \"day1\" / \"block-a-blue-day1-second-group-cam2.mp4\",\n",
    "#     DATA_DIR / 'depths' / 'day1' / \"group2-depth-cam2.mp4\",\n",
    "#     DATA_DIR / 'gaze_vectors' / \"gaze_vector_d1g2.csv\",\n",
    "#     np.array([30,110,30]),\n",
    "#     np.array([-3, 0, -9])*4\n",
    "# )\n",
    "\n",
    "# process(\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / \"videos\" / \"day2\" / \"block-a-blue-day2-first-group-cam2.mp4\",\n",
    "#     DATA_DIR / 'depths' / 'day2' / \"group1-depth-cam2.mp4\",\n",
    "#     DATA_DIR / 'gaze_vectors' / \"gaze_vector_d2g1.csv\",\n",
    "#     np.array([30,110,30]),\n",
    "#     np.array([-3, 0, -9])*4\n",
    "# )\n",
    "\n",
    "# process(\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / \"videos\" / \"day2\" / \"block-a-blue-day2-second-group-cam2.mp4\",\n",
    "#     DATA_DIR / 'depths' / 'day2' / \"group2-depth-cam2.mp4\",\n",
    "#     DATA_DIR / 'gaze_vectors' / \"gaze_vector_d2g2.csv\",\n",
    "#     np.array([30,110,30]),\n",
    "#     np.array([-3, 0, -9])*4\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
